{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988a9753",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T19:46:46.166731Z",
     "start_time": "2024-04-23T19:46:44.629169Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "candidates_input_path = 'data/medium_ubuntu_candidates.pkl'\n",
    "true_responses_input_path = 'data/medium_ubuntu_true_responses.pkl'\n",
    "\n",
    "rs_conv_prompts_input_path = 'prompts/rs_conv_prompts.pkl'\n",
    "rs_conv_struct_prompts_input_path = 'prompts/rs_conv_struct_prompts.pkl'\n",
    "rs_struct_summ_prompts_input_path = 'prompts/rs_struct_summ_prompts.pkl'\n",
    "rs_struct_desc_prompts_input_path = 'prompts/rs_struct_desc_prompts.pkl'\n",
    "rs_struct_summ_desc_prompts_input_path = 'prompts/rs_struct_summ_desc_prompts.pkl'\n",
    "\n",
    "rs_conv_prompts_output_path = 'output/rs_conv_out.pkl'\n",
    "rs_conv_struct_prompts_output_path = 'output/rs_conv_struct_out.pkl'\n",
    "rs_struct_summ_prompts_output_path = 'output/rs_struct_summ_out.pkl'\n",
    "rs_struct_desc_prompts_output_path = 'output/rs_struct_desc_out.pkl'\n",
    "rs_struct_summ_desc_prompts_output_path = 'output/rs_struct_summ_desc_out.pkl'\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1439871977969a0f"
  },
  {
   "cell_type": "markdown",
   "id": "9fa22970",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476f600",
   "metadata": {},
   "source": [
    "login ad hugginface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5affa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade huggingface_hub\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(\"YOUR_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64764dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig\n",
    "import transformers\n",
    "from tqdm.notebook import tqdm \n",
    "import torch\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3143a6",
   "metadata": {},
   "source": [
    "# Perplexity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec79a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from statistics import mean, median, stdev\n",
    "import os\n",
    "from os.path import exists, join, isdir\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, GenerationConfig\n",
    "import csv\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from typing import List\n",
    "from evaluate import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = load(\"perplexity\", module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(\n",
    "        predictions, batch_size: int = 16, add_start_token: bool = True, device=None, max_length=None\n",
    "    ):\n",
    "\n",
    "        if device is not None:\n",
    "            assert device in [\"gpu\", \"cpu\", \"cuda\"], \"device should be either gpu or cpu.\"\n",
    "            if device == \"gpu\":\n",
    "                device = \"cuda\"\n",
    "        else:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "        # if batch_size > 1 (which generally leads to padding being required), and\n",
    "        # if there is not an already assigned pad_token, assign an existing\n",
    "        # special token to also be the padding token\n",
    "        if tokenizer.pad_token is None and batch_size > 1:\n",
    "            existing_special_tokens = list(tokenizer.special_tokens_map_extended.values())\n",
    "            # check that the model already has at least one special token defined\n",
    "            assert (\n",
    "                len(existing_special_tokens) > 0\n",
    "            ), \"If batch_size > 1, model must have at least one special token to use for padding. Please use a different model or set batch_size=1.\"\n",
    "            # assign one of the special tokens to also be the pad token\n",
    "            tokenizer.add_special_tokens({\"pad_token\": existing_special_tokens[0]})\n",
    "\n",
    "        if add_start_token and max_length:\n",
    "            # leave room for <BOS> token to be added:\n",
    "            assert (\n",
    "                tokenizer.bos_token is not None\n",
    "            ), \"Input model must already have a BOS token if using add_start_token=True. Please use a different model, or set add_start_token=False\"\n",
    "            max_tokenized_len = max_length - 1\n",
    "        else:\n",
    "            max_tokenized_len = max_length\n",
    "\n",
    "        encodings = tokenizer(\n",
    "            predictions,\n",
    "            add_special_tokens=False,\n",
    "            padding=False,\n",
    "            truncation=True if max_tokenized_len else False,\n",
    "            max_length=max_tokenized_len,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(device)\n",
    "\n",
    "        encoded_texts = encodings[\"input_ids\"]\n",
    "        attn_masks = encodings[\"attention_mask\"]\n",
    "\n",
    "        # check that each input is long enough:\n",
    "        if add_start_token:\n",
    "            assert torch.all(torch.ge(attn_masks.sum(1), 1)), \"Each input text must be at least one token long.\"\n",
    "        else:\n",
    "            assert torch.all(\n",
    "                torch.ge(attn_masks.sum(1), 2)\n",
    "            ), \"When add_start_token=False, each input text must be at least two tokens long. Run with add_start_token=True if inputting strings of only one token, and remove all empty input strings.\"\n",
    "\n",
    "        ppls = []\n",
    "        loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "        for start_index in range(0, len(encoded_texts), batch_size):\n",
    "            end_index = min(start_index + batch_size, len(encoded_texts))\n",
    "            encoded_batch = encoded_texts[start_index:end_index]\n",
    "            attn_mask = attn_masks[start_index:end_index]\n",
    "\n",
    "            if add_start_token:\n",
    "                bos_tokens_tensor = torch.tensor([[tokenizer.bos_token_id]] * encoded_batch.size(dim=0)).to(device)\n",
    "                encoded_batch = torch.cat([bos_tokens_tensor, encoded_batch], dim=1)\n",
    "                attn_mask = torch.cat(\n",
    "                    [torch.ones(bos_tokens_tensor.size(), dtype=torch.int64).to(device), attn_mask], dim=1\n",
    "                )\n",
    "\n",
    "            labels = encoded_batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out_logits = model(encoded_batch, attention_mask=attn_mask).logits\n",
    "\n",
    "            shift_logits = out_logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            shift_attention_mask_batch = attn_mask[..., 1:].contiguous()\n",
    "\n",
    "            perplexity_batch = torch.exp(\n",
    "                (loss_fct(shift_logits.transpose(1, 2), shift_labels) * shift_attention_mask_batch).sum(1)\n",
    "                / shift_attention_mask_batch.sum(1)\n",
    "            )\n",
    "\n",
    "            ppls += perplexity_batch.tolist()\n",
    "\n",
    "        return {\"perplexities\": ppls, \"mean_perplexity\": np.mean(ppls)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def extract_probability(ppls, len_sents):\n",
    "    \"\"\"\n",
    "    Extract the probability from the perplexities and compute the log probability.\n",
    "\n",
    "    Parameters:\n",
    "    - ppls: Dictionary containing perplexities.\n",
    "    - len_sents: Length of the sentences.\n",
    "\n",
    "    Returns:\n",
    "    - log_prob: Log probability computed from the extracted perplexities.\n",
    "    \"\"\"\n",
    "    # Extract perplexities from the dictionary\n",
    "    ppls = ppls['perplexities']\n",
    "    \n",
    "    # Get the last perplexity\n",
    "    prob_last = ppls[0]\n",
    "    \n",
    "    # Calculate log probability\n",
    "    log_prob = math.log(prob_last) * (-len_sents)\n",
    "    \n",
    "    # Return the computed log probability\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_perplexity(tokenizer, sents):\n",
    "    \"\"\"\n",
    "    Compute the conditional perplexity for a sequence of sentences using a specified language model.\n",
    "\n",
    "    Parameters:\n",
    "    - tokenizer: An object implementing tokenization methods for the language model.\n",
    "    - sents: A list of sentences for which conditional perplexity needs to be computed.\n",
    "\n",
    "    Returns:\n",
    "    - cond_ppl: The computed conditional perplexity for the given sequence of sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables\n",
    "    c = ''\n",
    "    probabilities_1_to_n_1 = []\n",
    "    probabilities_1_to_n = []\n",
    "    cond_ppls = []\n",
    "    len_c = 0\n",
    "    \n",
    "    # Iterate through sentences to compute conditional perplexity\n",
    "    for i in range(1, len(sents)):\n",
    "        # Update accumulated context\n",
    "        c = str(c + sents[i-1])\n",
    "        t = str(c + sents[i])\n",
    "        \n",
    "        # Calculate lengths of context and current sentence in tokens\n",
    "        len_c = len_c + len(tokenizer.encode(sents[i-1]))\n",
    "        len_t = len_c + len(tokenizer.encode(sents[i]))\n",
    "        \n",
    "        # Extract probabilities for context c and current sentence t using the language model\n",
    "        p_c = extract_probability(compute_perplexity(predictions=[c], batch_size=1, add_start_token=False), len_c)\n",
    "        p_t = extract_probability(compute_perplexity(predictions=[t], batch_size=1, add_start_token=False), len_t)\n",
    "        \n",
    "        # Append probabilities to lists\n",
    "        probabilities_1_to_n_1.append(p_c)\n",
    "        probabilities_1_to_n.append(p_t)\n",
    "        \n",
    "        len_sents = [len(tokenizer.encode(i)) for i in sents]\n",
    "        \n",
    "        # Calculate conditional perplexity using the formula\n",
    "        cond_ppl = math.exp(1./len_sents[i]*(p_c - p_t))\n",
    "        \n",
    "        # Append the calculated conditional perplexity to the list\n",
    "        cond_ppls.append(cond_ppl)\n",
    "        \n",
    "    # Compute the mean of conditional perplexities\n",
    "    cond_ppl = mean(cond_ppls)\n",
    "    \n",
    "    # Return the computed conditional perplexity\n",
    "    return cond_ppl, cond_ppls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_conditional_perplexity(tokenizer, sents):\n",
    "    \"\"\"\n",
    "    Compute the conditional perplexity for a sentence follwoing another using a specified language model.\n",
    "\n",
    "    Parameters:\n",
    "    - tokenizer: An object implementing tokenization methods for the language model.\n",
    "    - sents: A list of sentences for which conditional perplexity needs to be computed.\n",
    "\n",
    "    Returns:\n",
    "    - cond_ppl: The computed conditional perplexity for the given sequence of sentences.\n",
    "    \"\"\"\n",
    "    c = str(sents[0])\n",
    "    t = str(c + sents[1])\n",
    "        \n",
    "    # Calculate lengths of context and current sentence in tokens\n",
    "    len_c = len(tokenizer.encode(sents[0]))\n",
    "    len_t = len_c + len(tokenizer.encode(sents[1]))\n",
    "        \n",
    "    # Extract probabilities for context c and current sentence t using the language model\n",
    "    p_c = extract_probability(compute_perplexity(predictions=[c], batch_size=1, add_start_token=False), len_c)\n",
    "    p_t = extract_probability(compute_perplexity(predictions=[t], batch_size=1, add_start_token=False), len_t)\n",
    "        \n",
    "        \n",
    "    len_sents = len(tokenizer.encode(sents[1]))\n",
    "        \n",
    "    # Calculate conditional perplexity using the formula\n",
    "    cond_ppl = math.exp(1./len_sents*(p_c - p_t))\n",
    "    \n",
    "    # Return the computed conditional perplexity\n",
    "    return cond_ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcdd12",
   "metadata": {},
   "source": [
    "# EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(candidates_input_path, 'rb') as f:\n",
    "    candidates = pickle.load(f)\n",
    "\n",
    "with open(true_responses_input_path, 'rb') as f:\n",
    "    true_responses = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4451f7",
   "metadata": {},
   "source": [
    "# CONV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ffeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(rs_conv_prompts_input_path, 'rb') as f:\n",
    "    rs_conv_prompts = pickle.load(f)\n",
    "    \n",
    "print(rs_conv_prompts[100])\n",
    "    \n",
    "rs_conv_output = []\n",
    "rs_conv_output_cppls = []\n",
    "rs_conv_output_distribution_cppls = [] \n",
    "\n",
    "for idx in range(len(rs_conv_prompts)):\n",
    "    \n",
    "    prompt = rs_conv_prompts[idx]\n",
    "    \n",
    "    responses = candidates[idx]\n",
    "    \n",
    "    cppls = []\n",
    "    \n",
    "    for r in responses:\n",
    "    \n",
    "        resp = r\n",
    "\n",
    "        cppl_value = compute_single_conditional_perplexity(tokenizer, [prompt, resp])\n",
    "\n",
    "        cppls.append(cppl_value)\n",
    "    \n",
    "    min_cppls = min(cppls)\n",
    "    res_out = cppls.index(min_cppls)\n",
    "    \n",
    "    rs_conv_output.append(res_out)\n",
    "    rs_conv_output_cppls.append(min_cppls)\n",
    "    rs_conv_output_distribution_cppls.append(cppls)\n",
    "\n",
    "#Right Or Wrong == row\n",
    "rs_conv_row = []\n",
    "\n",
    "for idx in range(len(rs_conv_output)):\n",
    "    if rs_conv_output[idx] == true_responses[idx]:\n",
    "        rs_conv_row.append(1)\n",
    "    else:\n",
    "        rs_conv_row.append(0)\n",
    "\n",
    "print(len(rs_conv_output))\n",
    "print(sum(rs_conv_row)/len(rs_conv_row))\n",
    "\n",
    "\n",
    "rs_conv_out = {\n",
    "    \"output\": rs_conv_output,\n",
    "    \"output_cppls\": rs_conv_output_cppls,\n",
    "    \"output_distribution_cppls\": rs_conv_output_distribution_cppls,\n",
    "    \"row\": rs_conv_row\n",
    "}\n",
    "\n",
    "\n",
    "with open(rs_conv_prompts_output_path, 'wb') as f:\n",
    "    pickle.dump(rs_conv_out, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd036155",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rs_conv_output))\n",
    "print(sum(rs_conv_row)/len(rs_conv_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395244d",
   "metadata": {},
   "source": [
    "# CONV + STRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeee54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(rs_conv_struct_prompts_input_path, 'rb') as f:\n",
    "    rs_conv_struct_prompts = pickle.load(f)\n",
    "\n",
    "print(rs_conv_struct_prompts[100])\n",
    "\n",
    "rs_conv_struct_output = []\n",
    "rs_conv_struct_output_cppls = []\n",
    "rs_conv_struct_output_distribution_cppls = []\n",
    "\n",
    "for idx in range(len(rs_conv_struct_prompts)):\n",
    "\n",
    "    prompt = rs_conv_struct_prompts[idx]\n",
    "\n",
    "    responses = candidates[idx]\n",
    "\n",
    "    cppls = []\n",
    "\n",
    "    for r in responses:\n",
    "\n",
    "        resp = r\n",
    "\n",
    "        cppl_value = compute_single_conditional_perplexity(tokenizer, [prompt, resp])\n",
    "\n",
    "        cppls.append(cppl_value)\n",
    "\n",
    "    min_cppls = min(cppls)\n",
    "    res_out = cppls.index(min_cppls)\n",
    "\n",
    "    rs_conv_struct_output.append(res_out)\n",
    "    rs_conv_struct_output_cppls.append(min_cppls)\n",
    "    rs_conv_struct_output_distribution_cppls.append(cppls)\n",
    "\n",
    "#Right Or Wrong == row\n",
    "rs_conv_struct_row = []\n",
    "\n",
    "for idx in range(len(rs_conv_struct_output)):\n",
    "    if rs_conv_struct_output[idx] == true_responses[idx]:\n",
    "        rs_conv_struct_row.append(1)\n",
    "    else:\n",
    "        rs_conv_struct_row.append(0)\n",
    "\n",
    "print(len(rs_conv_struct_output))\n",
    "print(sum(rs_conv_struct_row)/len(rs_conv_struct_row))\n",
    "\n",
    "\n",
    "rs_conv_struct_out = {\n",
    "    \"output\": rs_conv_struct_output,\n",
    "    \"output_cppls\": rs_conv_struct_output_cppls,\n",
    "    \"output_distribution_cppls\": rs_conv_struct_output_distribution_cppls,\n",
    "    \"row\": rs_conv_struct_row\n",
    "}\n",
    "\n",
    "\n",
    "with open(rs_conv_struct_prompts_output_path, 'wb') as f:\n",
    "    pickle.dump(rs_conv_struct_out, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7710c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rs_conv_struct_output))\n",
    "print(sum(rs_conv_struct_row)/len(rs_conv_struct_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66132dc5",
   "metadata": {},
   "source": [
    "# STRUCT + SUMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4851e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(rs_struct_summ_prompts_input_path, 'rb') as f:\n",
    "    rs_struct_summ_prompts = pickle.load(f)\n",
    "\n",
    "print(rs_struct_summ_prompts[100])\n",
    "\n",
    "rs_struct_summ_output = []\n",
    "rs_struct_summ_output_cppls = []\n",
    "rs_struct_summ_output_distribution_cppls = []\n",
    "\n",
    "for idx in range(len(rs_struct_summ_prompts)):\n",
    "\n",
    "    prompt = rs_struct_summ_prompts[idx]\n",
    "\n",
    "    responses = candidates[idx]\n",
    "\n",
    "    cppls = []\n",
    "\n",
    "    for r in responses:\n",
    "\n",
    "        resp = r\n",
    "\n",
    "        cppl_value = compute_single_conditional_perplexity(tokenizer, [prompt, resp])\n",
    "\n",
    "        cppls.append(cppl_value)\n",
    "\n",
    "    min_cppls = min(cppls)\n",
    "    res_out = cppls.index(min_cppls)\n",
    "\n",
    "    rs_struct_summ_output.append(res_out)\n",
    "    rs_struct_summ_output_cppls.append(min_cppls)\n",
    "    rs_struct_summ_output_distribution_cppls.append(cppls)\n",
    "\n",
    "#Right Or Wrong == row\n",
    "rs_struct_summ_row = []\n",
    "\n",
    "for idx in range(len(rs_struct_summ_output)):\n",
    "    if rs_struct_summ_output[idx] == true_responses[idx]:\n",
    "        rs_struct_summ_row.append(1)\n",
    "    else:\n",
    "        rs_struct_summ_row.append(0)\n",
    "\n",
    "print(len(rs_struct_summ_output))\n",
    "print(sum(rs_struct_summ_row)/len(rs_struct_summ_row))\n",
    "\n",
    "\n",
    "rs_struct_summ_out = {\n",
    "    \"output\": rs_struct_summ_output,\n",
    "    \"output_cppls\": rs_struct_summ_output_cppls,\n",
    "    \"output_distribution_cppls\": rs_struct_summ_output_distribution_cppls,\n",
    "    \"row\": rs_struct_summ_row\n",
    "}\n",
    "\n",
    "\n",
    "with open(rs_struct_summ_prompts_output_path, 'wb') as f:\n",
    "    pickle.dump(rs_struct_summ_out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db61fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rs_struct_summ_output))\n",
    "print(sum(rs_struct_summ_row)/len(rs_struct_summ_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead2a04",
   "metadata": {},
   "source": [
    "# STRUCT + DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac14259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(rs_struct_desc_prompts_input_path, 'rb') as f:\n",
    "    rs_struct_desc_prompts = pickle.load(f)\n",
    "\n",
    "print(rs_struct_desc_prompts[100])\n",
    "\n",
    "rs_struct_desc_output = []\n",
    "rs_struct_desc_output_cppls = []\n",
    "rs_struct_desc_output_distribution_cppls = []\n",
    "\n",
    "for idx in range(len(rs_struct_desc_prompts)):\n",
    "\n",
    "    prompt = rs_struct_desc_prompts[idx]\n",
    "\n",
    "    responses = candidates[idx]\n",
    "\n",
    "    cppls = []\n",
    "\n",
    "    for r in responses:\n",
    "\n",
    "        resp = r\n",
    "\n",
    "        cppl_value = compute_single_conditional_perplexity(tokenizer, [prompt, resp])\n",
    "\n",
    "        cppls.append(cppl_value)\n",
    "\n",
    "    min_cppls = min(cppls)\n",
    "    res_out = cppls.index(min_cppls)\n",
    "\n",
    "    rs_struct_desc_output.append(res_out)\n",
    "    rs_struct_desc_output_cppls.append(min_cppls)\n",
    "    rs_struct_desc_output_distribution_cppls.append(cppls)\n",
    "\n",
    "#Right Or Wrong == row\n",
    "rs_struct_desc_row = []\n",
    "\n",
    "for idx in range(len(rs_struct_desc_output)):\n",
    "    if rs_struct_desc_output[idx] == true_responses[idx]:\n",
    "        rs_struct_desc_row.append(1)\n",
    "    else:\n",
    "        rs_struct_desc_row.append(0)\n",
    "\n",
    "print(len(rs_struct_desc_output))\n",
    "print(sum(rs_struct_desc_row)/len(rs_struct_desc_row))\n",
    "\n",
    "\n",
    "rs_struct_desc_out = {\n",
    "    \"output\": rs_struct_desc_output,\n",
    "    \"output_cppls\": rs_struct_desc_output_cppls,\n",
    "    \"output_distribution_cppls\": rs_struct_desc_output_distribution_cppls,\n",
    "    \"row\": rs_struct_desc_row\n",
    "}\n",
    "\n",
    "\n",
    "with open(rs_struct_desc_prompts_output_path, 'wb') as f:\n",
    "    pickle.dump(rs_struct_desc_out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877992bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rs_struct_desc_output))\n",
    "print(sum(rs_struct_desc_row)/len(rs_struct_desc_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e6c533",
   "metadata": {},
   "source": [
    "# STRUCT + SUMM + DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(rs_struct_summ_desc_prompts_input_path, 'rb') as f:\n",
    "    rs_struct_summ_desc_prompts = pickle.load(f)\n",
    "\n",
    "print(rs_struct_summ_desc_prompts[100])\n",
    "\n",
    "rs_struct_summ_desc_output = []\n",
    "rs_struct_summ_desc_output_cppls = []\n",
    "rs_struct_summ_desc_output_distribution_cppls = []\n",
    "\n",
    "for idx in range(len(rs_struct_summ_desc_prompts)):\n",
    "\n",
    "    prompt = rs_struct_summ_desc_prompts[idx]\n",
    "\n",
    "    responses = candidates[idx]\n",
    "\n",
    "    cppls = []\n",
    "\n",
    "    for r in responses:\n",
    "\n",
    "        resp = r\n",
    "\n",
    "        cppl_value = compute_single_conditional_perplexity(tokenizer, [prompt, resp])\n",
    "\n",
    "        cppls.append(cppl_value)\n",
    "\n",
    "    min_cppls = min(cppls)\n",
    "    res_out = cppls.index(min_cppls)\n",
    "\n",
    "    rs_struct_summ_desc_output.append(res_out)\n",
    "    rs_struct_summ_desc_output_cppls.append(min_cppls)\n",
    "    rs_struct_summ_desc_output_distribution_cppls.append(cppls)\n",
    "\n",
    "#Right Or Wrong == row\n",
    "rs_struct_summ_desc_row = []\n",
    "\n",
    "for idx in range(len(rs_struct_summ_desc_output)):\n",
    "    if rs_struct_summ_desc_output[idx] == true_responses[idx]:\n",
    "        rs_struct_summ_desc_row.append(1)\n",
    "    else:\n",
    "        rs_struct_summ_desc_row.append(0)\n",
    "\n",
    "print(len(rs_struct_summ_desc_output))\n",
    "print(sum(rs_struct_summ_desc_row)/len(rs_struct_summ_desc_row))\n",
    "\n",
    "\n",
    "rs_struct_summ_desc_out = {\n",
    "    \"output\": rs_struct_summ_desc_output,\n",
    "    \"output_cppls\": rs_struct_summ_desc_output_cppls,\n",
    "    \"output_distribution_cppls\": rs_struct_summ_desc_output_distribution_cppls,\n",
    "    \"row\": rs_struct_summ_desc_row\n",
    "}\n",
    "\n",
    "\n",
    "with open(rs_struct_summ_desc_prompts_output_path, 'wb') as f:\n",
    "    pickle.dump(rs_struct_summ_desc_out, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0df00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rs_struct_summ_desc_output))\n",
    "print(sum(rs_struct_summ_desc_row)/len(rs_struct_summ_desc_row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
